{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ad028b-72b7-43ed-aa78-96fd4e518040",
   "metadata": {
    "id": "13ad028b-72b7-43ed-aa78-96fd4e518040"
   },
   "source": [
    "# Assignment: Exploratory Data Analysis\n",
    "### `! git clone https://github.com/ds4e/visualization`\n",
    "### Do One."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bcd96-2834-41a4-80fe-d354b4277fd9",
   "metadata": {
    "id": "c11bcd96-2834-41a4-80fe-d354b4277fd9"
   },
   "source": [
    "**Q1.** This question provides some practice doing exploratory data analysis and visualization.\n",
    "\n",
    "The \"relevant\" variables for this question are:\n",
    "  - `level` - Level of institution (4-year, 2-year)\n",
    "  - `aid_value` - The average amount of student aid going to undergraduate recipients\n",
    "  - `control` - Public, Private not-for-profit, Private for-profit\n",
    "  - `grad_100_value` - percentage of first-time, full-time, degree-seeking undergraduates who complete a degree or certificate program within 100 percent of expected time (bachelor's-seeking group at 4-year institutions)\n",
    "\n",
    "1. Load the `./data/college_completion.csv` data with Pandas.\n",
    "2. What are are the dimensions of the data? How many observations are there? What are the variables included? Use `.head()` to examine the first few rows of data.\n",
    "3. Cross tabulate `control` and `level`. Describe the patterns you see.\n",
    "4. For `grad_100_value`, create a histogram, kernel density plot, boxplot, and statistical description.\n",
    "5. For `grad_100_value`, create a grouped kernel density plot by `control` and by `level`. Describe what you see. Use `groupby` and `.describe` to make grouped calculations of statistical descriptions of `grad_100_value` by `level` and `control`. Which institutions appear to have the best graduation rates?\n",
    "6. Create a new variable, `df['levelXcontrol']=df['level']+', '+df['control']` that interacts level and control. Make a grouped kernel density plot. Which institutions appear to have the best graduation rates?\n",
    "7. Make a kernel density plot of `aid_value`. Now group your graph by `level` and `control`. What explains the shape of the graph? Use `groupby` and `.describe` to make grouped calculations of statistical descriptions of `aid_value` by `level` and `control`.\n",
    "8. Make a scatterplot of `grad_100_value` by `aid_value`. Describe what you see. Now make the same plot, grouping by `level` and then `control`. Describe what you see. For which kinds of institutions does aid seem to increase graduation rates?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e54a37-63fb-4df9-af65-81ee53ae00fe",
   "metadata": {},
   "source": [
    "**Q2.** Go to https://data.cms.gov/search.\n",
    "1. Pick a dataset about something you are interested in. Download the data and data dictionary. If you really can't decide, you can always use this one: https://data.cms.gov/medicare-current-beneficiary-survey-mcbs/medicare-current-beneficiary-survey-data\n",
    "3. Does the data dictionary document how missings are handled? For categorical variables, does it describe the possible values and missing value codes? For the numeric variables, does it describe how missing values are handled? Summarize your opinion of the data dictionary.\n",
    "4. Pick out a few interesting variables, and explain why you find them jointly interesting. Clean those variables, documenting your choices by commenting in the code or in a markdown chunk in a notebook.\n",
    "5. For the variables you select, make a boxplot for each numeric variable and a bar graph for each categorical variable. Do you see any outliers?\n",
    "6. Create a histogram or kernel density plot, and explain what you see. Do the results require any transformations to rescale them? \n",
    "7. Create a scatter plot, and describe the relationship you see.\n",
    "8. Create a table (cross tabulation, variance-covariance, or a `.describe()` five-number summary), and explain what you see."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21522e42",
   "metadata": {},
   "source": [
    "**Q3.** This is a case study about understanding and visualizing risk over time, involving a dataset with information about breast cancer mortality rates over time, conditional on different treatments.\n",
    "\n",
    "1. Load the `./data/Breast Cancer METABRIC.csv` dataset. It has a bunch of interesting variables, but the mains of interest for this question are `Overall Survival (Months)`, which is  and `Overall Survival Survival Status`, which records whether the patient is Alive or Deceased.\n",
    "2. Make one kernel density plot of `Overall Survival (Months)`, and a second conditional on `Overall Survival Status`. Interpret these plots. What patterns do you see? \n",
    "\n",
    "3. The **hazard rate** gives the instantaneous risk of an event occurring, given that it hasn't already happened. It is defined as\n",
    "$$\n",
    "h(t) = \\dfrac{f(t)}{1-F(t)}\n",
    "$$\n",
    "where $F(t)$ is the distribution of arrival times and $f(t)=F'(t)$ is the density of arrival times. Roughly, conditional on $T \\ge t$, what is the probability that $T=t$? The cumulative hazard is given by\n",
    "$$\n",
    "H(t) = \\int_0^t h(z) dz.\n",
    "$$\n",
    "The following function computes the hazard rate and cumulative hazard using something called the Nelson-Ahlen estimator. Run your data through it. Interpret the plots for the hazard rate and cumulative hazard rate. What patterns do you see?\n",
    "\n",
    "```\n",
    "def hazard(df):\n",
    "    \"\"\" Compute cumulative hazard rate using Nelson-Ahlen estimator. \"\"\"\n",
    "    at_risk = df.shape[0]\n",
    "    arrivals = df['survival'].sort_values().dropna().tolist()\n",
    "    hazard_rate = []\n",
    "    times = []\n",
    "    for t in arrivals:\n",
    "        select = (df['survival']==t)*(df['Overall Survival Status']=='Deceased')\n",
    "        deaths_t = df[select].shape[0]\n",
    "        if deaths_t > 0:\n",
    "            hazard_rate.append(deaths_t/at_risk)\n",
    "            times.append(t)\n",
    "            at_risk -= deaths_t\n",
    "    cumulative_hazard = np.cumsum(hazard_rate)\n",
    "    return cumulative_hazard, times, hazard_rate\n",
    "```\n",
    "\n",
    "4. There are lots of additional categorical variables in the METABRIC dataset. Pick a categorical variable, and plot the hazard rate and cumulative hazard for each category. Do you see any interesting patterns? Is one group more likely to survive, or do their hazard rates cross over time?\n",
    "5. These plots are very helpful for understanding how patients respond to treatment. Discuss how they might be used in practice, to help doctors and patients make decisions about care."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea89b847",
   "metadata": {},
   "source": [
    "**Q4.** Write your own function to make a kernel density plot.\n",
    "\n",
    "- The user should pass in a Pandas series or Numpy array.\n",
    "- The default kernel should be Gaussian, but include the uniform/bump and Epanechnikov as alternatives.\n",
    "- The default bandwidth should be the Silverman plug-in, but allow the user to specify an alternative.\n",
    "- You can use Matplotlib or Seaborn's `.lineplot`, but not an existing function that creates kernel density plots.\n",
    "\n",
    "You will have to make a lot of choices and experiment with getting errors. Embrace the challenge and track your choices in the comments in your code.\n",
    "\n",
    "Use a data set from class to show that your function works, and compare it with the Seaborn `kdeplot`.\n",
    "\n",
    "We covered the Gaussian,\n",
    "$$\n",
    "k(z) = \\dfrac{1}{\\sqrt{2\\pi}}e^{-z^2/2}\n",
    "$$\n",
    "and uniform \n",
    "$$\n",
    "k(z) = \\begin{cases} \n",
    "\\frac{1}{2}, & |z| \\le 1 \\\\\n",
    "0, & |z|>1\n",
    "\\end{cases}\n",
    "$$\n",
    "kernels in class, but the Epanechnikov kernel is \n",
    "$$\n",
    "k(z) = \\begin{cases} \n",
    "\\frac{3}{4} (1-z^2), & |z| \\le 1 \\\\\n",
    "0, & |z|>1.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "In order to make your code run reasonably quickly, consider using the `pdist` or `cdist` functions from SciPy to make distance calculations for arrays of points. The other leading alternative is to thoughtfully use NumPy's broadcasting features. Writing `for` loops will be slow, but that's fine."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
